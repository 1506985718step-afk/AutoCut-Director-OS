"""åˆ†æè·¯ç”± - å¤„ç†ç´ æåˆ†æè¯·æ±‚"""
from fastapi import APIRouter, UploadFile, File, HTTPException, Form
from fastapi.responses import JSONResponse
from pathlib import Path
import json
import shutil
from typing import Optional

from ..config import settings
from ..core.job_store import JobStore
from ..tools.asr_whisper import transcribe_audio
from ..tools.scene_from_edl import parse_edl_to_scenes
from ..tools.scene_from_xml import parse_xml_to_scenes

router = APIRouter()
job_store = JobStore()


@router.post("/story")
async def analyze_story(
    video_file: UploadFile = File(...),
    duration_target: int = Form(30),
    style_preference: Optional[str] = Form(None),
    platform: str = Form("douyin")
):
    """
    å…¨è‡ªåŠ¨å¯¼æ¼”æ¨¡å¼ï¼ˆBæ¨¡å¼ï¼‰ï¼šæ‰”è¿›è§†é¢‘ï¼Œåå‡ºæ•…äº‹
    
    å®Œæ•´æµç¨‹ï¼š
    1. è§†é¢‘ä¸Šä¼  â†’ åœºæ™¯æ£€æµ‹
    2. VisualAnalyzer â†’ æ‰“æ ‡ç­¾
    3. VisualStoryteller â†’ æ„æ€æ•…äº‹
    4. LLMDirector â†’ ç”Ÿæˆ DSL
    5. è¿”å›å®Œæ•´å‰ªè¾‘æ–¹æ¡ˆ
    
    Args:
        video_file: è§†é¢‘æ–‡ä»¶
        duration_target: ç›®æ ‡æ—¶é•¿ï¼ˆç§’ï¼‰
        style_preference: é£æ ¼åå¥½ï¼ˆå¯é€‰ï¼‰
        platform: ç›®æ ‡å¹³å°
    
    Returns:
        {
            "success": true,
            "job_id": "job_xxx",
            "story": {...},
            "dsl": {...},
            "message": "å…¨è‡ªåŠ¨åˆ†æå®Œæˆ"
        }
    """
    try:
        from ..tools.visual_analyzer_factory import analyze_scenes_auto
        from ..core.visual_storyteller import VisualStoryteller
        from ..core.llm_engine import LLMDirector
        from ..tools.scene_from_edl import detect_scenes_from_video
        
        print("\nğŸ¬ å…¨è‡ªåŠ¨å¯¼æ¼”æ¨¡å¼å¯åŠ¨...")
        
        # 1. åˆ›å»ºä»»åŠ¡
        job_id = job_store.create_job()
        job_dir = settings.JOBS_DIR / job_id
        
        # 2. ä¿å­˜è§†é¢‘
        video_path = job_dir / video_file.filename
        with open(video_path, "wb") as f:
            shutil.copyfileobj(video_file.file, f)
        
        print(f"  âœ“ è§†é¢‘å·²ä¿å­˜: {video_path}")
        
        # 3. åœºæ™¯æ£€æµ‹ï¼ˆç®€åŒ–ç‰ˆï¼šä½¿ç”¨å›ºå®š FPSï¼‰
        print("\n[1/5] åœºæ™¯æ£€æµ‹...")
        # TODO: å®ç°çœŸæ­£çš„åœºæ™¯æ£€æµ‹
        # æš‚æ—¶ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
        from ..models.schemas import ScenesJSON, ScenesMeta, ScenesMedia, Scene
        
        # è·å–è§†é¢‘ä¿¡æ¯
        import subprocess
        result = subprocess.run(
            ["ffprobe", "-v", "error", "-select_streams", "v:0",
             "-show_entries", "stream=duration,r_frame_rate",
             "-of", "json", str(video_path)],
            capture_output=True,
            text=True
        )
        
        video_info = json.loads(result.stdout)
        duration = float(video_info["streams"][0]["duration"])
        fps_str = video_info["streams"][0]["r_frame_rate"]
        fps = eval(fps_str)  # "30/1" -> 30.0
        
        # ç®€å•åˆ†æ®µï¼šæ¯ 5 ç§’ä¸€ä¸ªåœºæ™¯
        scenes = []
        segment_duration = 5.0
        num_segments = int(duration / segment_duration)
        
        for i in range(num_segments):
            start_sec = i * segment_duration
            end_sec = min((i + 1) * segment_duration, duration)
            start_frame = int(start_sec * fps)
            end_frame = int(end_sec * fps)
            
            scenes.append(Scene(
                scene_id=f"S{i+1:04d}",
                start_frame=start_frame,
                end_frame=end_frame,
                start_tc=f"00:00:{int(start_sec):02d}:00",
                end_tc=f"00:00:{int(end_sec):02d}:00"
            ))
        
        scenes_data = ScenesJSON(
            meta=ScenesMeta(fps=fps, source="auto_detect"),
            media=ScenesMedia(primary_clip_path=str(video_path)),
            scenes=scenes
        )
        
        print(f"  âœ“ æ£€æµ‹åˆ° {len(scenes)} ä¸ªåœºæ™¯")
        
        # 4. è§†è§‰åˆ†æ
        print("\n[2/5] è§†è§‰åˆ†æï¼ˆAI çœ¼ç›ï¼‰...")
        scenes_with_visual = analyze_scenes_auto(
            scenes_data,
            str(video_path),
            max_scenes=min(10, len(scenes))  # é™åˆ¶æ•°é‡ä»¥æ§åˆ¶æˆæœ¬
        )
        
        # ä¿å­˜ scenes_with_visual.json
        scenes_path = job_dir / "scenes_with_visual.json"
        with open(scenes_path, 'w', encoding='utf-8') as f:
            json.dump(scenes_with_visual.model_dump(), f, indent=2, ensure_ascii=False)
        
        # 5. æ•…äº‹æ„æ€
        print("\n[3/5] æ•…äº‹æ„æ€ï¼ˆAI å¤§è„‘ï¼‰...")
        storyteller = VisualStoryteller()
        story_result = storyteller.generate_story_from_visuals(
            scenes_with_visual,
            duration_target=duration_target,
            style_preference=style_preference
        )
        
        # ä¿å­˜æ•…äº‹ç»“æœ
        story_path = job_dir / "story_result.json"
        story_output = {
            "theme": story_result['theme'],
            "logic": story_result['logic'],
            "narrative_style": story_result['narrative_style'],
            "suggested_bgm_mood": story_result['suggested_bgm_mood'],
            "clustering": story_result['clustering'],
            "alternative_themes": story_result.get('alternative_themes', []),
            "generated_transcript": story_result['generated_transcript'].model_dump()
        }
        
        with open(story_path, 'w', encoding='utf-8') as f:
            json.dump(story_output, f, indent=2, ensure_ascii=False)
        
        # 6. ç”Ÿæˆ DSL
        print("\n[4/5] ç”Ÿæˆå‰ªè¾‘æ–¹æ¡ˆï¼ˆAI å¯¼æ¼”ï¼‰...")
        dsl = storyteller.generate_dsl_from_story(
            scenes_with_visual,
            story_result,
            platform=platform
        )
        
        # ä¿å­˜ DSL
        dsl_path = job_dir / "editing_dsl.json"
        with open(dsl_path, 'w', encoding='utf-8') as f:
            json.dump(dsl, f, indent=2, ensure_ascii=False)
        
        print("\n[5/5] å®Œæˆï¼")
        print(f"  âœ“ ä¸»é¢˜: {story_result['theme']}")
        print(f"  âœ“ é£æ ¼: {story_result['narrative_style']}")
        print(f"  âœ“ æ—¶é—´çº¿ç‰‡æ®µ: {len(dsl.get('editing_plan', {}).get('timeline', []))}")
        
        return JSONResponse(content={
            "success": True,
            "job_id": job_id,
            "story": {
                "theme": story_result['theme'],
                "logic": story_result['logic'],
                "narrative_style": story_result['narrative_style'],
                "suggested_bgm_mood": story_result['suggested_bgm_mood']
            },
            "dsl_summary": {
                "timeline_items": len(dsl.get('editing_plan', {}).get('timeline', [])),
                "platform": platform,
                "resolution": dsl.get('export', {}).get('resolution')
            },
            "paths": {
                "scenes": str(scenes_path),
                "story": str(story_path),
                "dsl": str(dsl_path)
            },
            "message": f"å…¨è‡ªåŠ¨åˆ†æå®Œæˆï¼š{story_result['theme']}"
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"å…¨è‡ªåŠ¨åˆ†æå¤±è´¥: {str(e)}")


@router.post("/analyze")
async def analyze(
    edl_file: Optional[UploadFile] = File(None),
    xml_file: Optional[UploadFile] = File(None),
    audio_file: Optional[UploadFile] = File(None),
    srt_file: Optional[UploadFile] = File(None)
):
    """
    åˆ†æä¸Šä¼ çš„ç´ æï¼Œç”Ÿæˆ scenes.json å’Œ transcript.json
    
    Stage A (MVP): EDL -> scenes.json
    Stage A': FCPXML -> scenes.json (å¢å¼º)
    Stage B: Audio -> transcript.json (Whisper ASR)
    Stage C: SRT -> transcript.json (ç›´æ¥å¯¼å…¥)
    """
    # åˆ›å»ºæ–°ä»»åŠ¡
    job_id = job_store.create_job()
    job_dir = settings.JOBS_DIR / job_id
    
    result = {
        "job_id": job_id,
        "artifacts": {}
    }
    
    try:
        # Stage A: EDL -> scenes.json (MVP æ¨è)
        if edl_file:
            edl_path = job_dir / edl_file.filename
            with open(edl_path, "wb") as f:
                shutil.copyfileobj(edl_file.file, f)
            
            # TODO: ä»è¯·æ±‚å‚æ•°è·å– fps å’Œ primary_clip_path
            fps = 30  # é»˜è®¤ 30fps
            primary_clip_path = "D:/Footage/input.mp4"  # éœ€è¦ç”¨æˆ·æä¾›
            
            scenes = parse_edl_to_scenes(str(edl_path), fps, primary_clip_path)
            scenes_path = job_dir / "scenes.json"
            with open(scenes_path, "w", encoding="utf-8") as f:
                json.dump(scenes, f, indent=2, ensure_ascii=False)
            
            result["artifacts"]["scenes"] = "scenes.json"
            job_store.update_job(job_id, status="analyzing", progress=30)
        
        # Stage A': FCPXML -> scenes.json
        if xml_file:
            xml_path = job_dir / xml_file.filename
            with open(xml_path, "wb") as f:
                shutil.copyfileobj(xml_file.file, f)
            
            scenes = parse_xml_to_scenes(str(xml_path))
            scenes_path = job_dir / "scenes.json"
            with open(scenes_path, "w", encoding="utf-8") as f:
                json.dump(scenes, f, indent=2, ensure_ascii=False)
            
            result["artifacts"]["scenes"] = "scenes.json"
            job_store.update_job(job_id, status="analyzing", progress=30)
        
        # Stage B: Whisper ASR -> transcript.json
        if audio_file:
            audio_path = job_dir / audio_file.filename
            with open(audio_path, "wb") as f:
                shutil.copyfileobj(audio_file.file, f)
            
            job_store.update_job(job_id, status="transcribing", progress=50)
            transcript = transcribe_audio(str(audio_path))
            
            transcript_path = job_dir / "transcript.json"
            with open(transcript_path, "w", encoding="utf-8") as f:
                json.dump(transcript, f, indent=2, ensure_ascii=False)
            
            result["artifacts"]["transcript"] = "transcript.json"
            job_store.update_job(job_id, status="analyzing", progress=80)
        
        # Stage C: SRT -> transcript.json (ç›´æ¥å¯¼å…¥)
        if srt_file:
            srt_path = job_dir / srt_file.filename
            with open(srt_path, "wb") as f:
                shutil.copyfileobj(srt_file.file, f)
            
            # è§£æ SRT ä¸º transcript.json
            from ..tools.srt_parser import parse_srt_to_transcript
            transcript = parse_srt_to_transcript(str(srt_path))
            
            transcript_path = job_dir / "transcript.json"
            with open(transcript_path, "w", encoding="utf-8") as f:
                json.dump(transcript, f, indent=2, ensure_ascii=False)
            
            result["artifacts"]["transcript"] = "transcript.json"
        
        if not result["artifacts"]:
            raise HTTPException(status_code=400, detail="è‡³å°‘éœ€è¦æä¾›ä¸€ä¸ªæ–‡ä»¶")
        
        job_store.update_job(job_id, status="completed", progress=100, result=result)
        return JSONResponse(content=result)
        
    except Exception as e:
        job_store.update_job(job_id, status="failed", error=str(e))
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/job/{job_id}")
async def get_job_status(job_id: str):
    """è·å–ä»»åŠ¡çŠ¶æ€"""
    job = job_store.get_job(job_id)
    if not job:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    return job


@router.get("/job/{job_id}/artifact/{artifact_name}")
async def get_artifact(job_id: str, artifact_name: str):
    """ä¸‹è½½ä»»åŠ¡äº§ç‰©"""
    job_dir = settings.JOBS_DIR / job_id
    artifact_path = job_dir / artifact_name
    
    if not artifact_path.exists():
        raise HTTPException(status_code=404, detail="äº§ç‰©ä¸å­˜åœ¨")
    
    from fastapi.responses import FileResponse
    return FileResponse(artifact_path)
