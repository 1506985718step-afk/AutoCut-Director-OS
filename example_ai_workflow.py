"""å®Œæ•´ AI å·¥ä½œæµç¤ºä¾‹ - ä»ç´ æåˆ°æˆç‰‡"""
import json
from pathlib import Path
from app.tools.scene_from_edl import parse_edl_to_scenes
from app.tools.asr_whisper import transcribe_audio
from app.core.llm_engine import LLMDirector
from app.models.schemas import ScenesJSON, TranscriptJSON, DSLValidator
from app.executor.actions import (
    create_timeline,
    append_scene,
    render_subtitles,
    add_text_overlay,
    add_music,
    export_mp4
)
from app.executor.runner import run_actions


def ai_workflow_demo():
    """
    å®Œæ•´ AI å·¥ä½œæµæ¼”ç¤º
    
    æµç¨‹ï¼š
    1. EDL â†’ scenes.jsonï¼ˆåœºæ™¯åˆ‡åˆ†ï¼‰
    2. Audio â†’ transcript.jsonï¼ˆè¯­éŸ³è½¬å½•ï¼‰
    3. LLM â†’ editing_dsl.jsonï¼ˆAI ç”Ÿæˆå‰ªè¾‘è„šæœ¬ï¼‰
    4. DSL â†’ Actionsï¼ˆè½¬æ¢ä¸ºæ‰§è¡ŒåŠ¨ä½œï¼‰
    5. Resolve â†’ æ‰§è¡Œå‰ªè¾‘ï¼ˆè‡ªåŠ¨åŒ–å‰ªè¾‘ï¼‰
    """
    print("=" * 70)
    print("AutoCut Director - å®Œæ•´ AI å·¥ä½œæµæ¼”ç¤º")
    print("=" * 70)
    
    # ========================================================================
    # Stage 1: åœºæ™¯åˆ‡åˆ†ï¼ˆEDL â†’ scenes.jsonï¼‰
    # ========================================================================
    print("\n[Stage 1] åœºæ™¯åˆ‡åˆ† - EDL â†’ scenes.json")
    print("-" * 70)
    
    edl_path = "examples/test.edl"
    primary_clip = "D:/Footage/input.mp4"  # è¯·æ›¿æ¢ä¸ºå®é™…è·¯å¾„
    fps = 30
    
    print(f"è§£æ EDL: {edl_path}")
    scenes_data = parse_edl_to_scenes(edl_path, fps, primary_clip)
    scenes = ScenesJSON(**scenes_data)
    
    print(f"âœ“ è§£ææˆåŠŸï¼Œç”Ÿæˆ {len(scenes.scenes)} ä¸ªåœºæ™¯")
    for scene in scenes.scenes[:3]:
        print(f"  - {scene.scene_id}: {scene.start_tc} â†’ {scene.end_tc}")
    
    # ä¿å­˜ scenes.json
    scenes_path = Path("examples/scenes.ai_workflow.json")
    scenes_path.write_text(
        json.dumps(scenes_data, ensure_ascii=False, indent=2),
        encoding="utf-8"
    )
    print(f"âœ“ ä¿å­˜åˆ°: {scenes_path}")
    
    # ========================================================================
    # Stage 2: è¯­éŸ³è½¬å½•ï¼ˆAudio â†’ transcript.jsonï¼‰
    # ========================================================================
    print("\n[Stage 2] è¯­éŸ³è½¬å½• - Audio â†’ transcript.json")
    print("-" * 70)
    
    audio_path = "D:/Footage/input.mp4"  # å¯ä»¥ç›´æ¥ç”¨è§†é¢‘æ–‡ä»¶
    
    print(f"è½¬å½•éŸ³é¢‘: {audio_path}")
    print("(ä½¿ç”¨ Whisper æ¨¡å‹ï¼Œå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ...)")
    
    # å®é™…é¡¹ç›®ä¸­å–æ¶ˆæ³¨é‡Š
    # transcript_data = transcribe_audio(audio_path, model="base", language="zh")
    # transcript = TranscriptJSON(**transcript_data)
    
    # æ¼”ç¤ºç”¨ï¼šåŠ è½½ç¤ºä¾‹
    transcript_path = Path("examples/transcript.v1.json")
    transcript_data = json.loads(transcript_path.read_text(encoding="utf-8"))
    transcript = TranscriptJSON(**transcript_data)
    
    print(f"âœ“ è½¬å½•æˆåŠŸï¼Œç”Ÿæˆ {len(transcript.segments)} ä¸ªå­—å¹•æ®µ")
    for seg in transcript.segments[:3]:
        print(f"  - [{seg.start:.1f}s] {seg.text}")
    
    # ========================================================================
    # Stage 3: AI ç”Ÿæˆå‰ªè¾‘è„šæœ¬ï¼ˆLLM â†’ editing_dsl.jsonï¼‰
    # ========================================================================
    print("\n[Stage 3] AI ç”Ÿæˆå‰ªè¾‘è„šæœ¬ - LLM â†’ editing_dsl.json")
    print("-" * 70)
    
    print("è°ƒç”¨ LLM ç”Ÿæˆå‰ªè¾‘è„šæœ¬...")
    
    try:
        director = LLMDirector()
        
        style_prompt = """
æŠ–éŸ³çˆ†æ¬¾é£æ ¼ï¼š
1. å¼€å¤´ 3 ç§’å¿…é¡»æœ‰å¼ºçƒˆçš„ Hookï¼ˆé’©å­ï¼‰ï¼Œå¸å¼•è§‚ä¼—åœç•™
2. èŠ‚å¥å¿«ï¼Œæ¯ 3-5 ç§’åˆ‡æ¢ç”»é¢æˆ–æ–‡å­—
3. åˆ é™¤æ‰€æœ‰åºŸè¯ã€åœé¡¿ã€é‡å¤å†…å®¹
4. æ–‡å­—å åŠ è¦ç®€çŸ­æœ‰åŠ›ï¼ˆ5-8 å­—ï¼‰ï¼Œçªå‡ºå…³é”®ä¿¡æ¯
5. å¼ºè°ƒæ•°å­—å’Œå¯¹æ¯”ï¼ˆå¦‚"90%çš„äºº"ã€"ç¬¬ä¸€æ­¥"ï¼‰
6. æ€»æ—¶é•¿æ§åˆ¶åœ¨ 30-60 ç§’
"""
        
        dsl = director.generate_editing_dsl(scenes, transcript, style_prompt)
        
        print("âœ“ AI ç”ŸæˆæˆåŠŸï¼")
        
        # éªŒè¯ DSL
        print("\néªŒè¯ DSL ç¡¬è§„åˆ™...")
        errors = DSLValidator.validate_dsl_against_scenes(dsl, scenes_data)
        
        if errors:
            print("âœ— éªŒè¯å¤±è´¥ï¼ˆAI å¹»è§‰æ£€æµ‹ï¼‰ï¼š")
            for err in errors:
                print(f"  - {err}")
            return False
        
        print("âœ“ éªŒè¯é€šè¿‡ï¼AI æ²¡æœ‰å¹»è§‰")
        
        # ä¿å­˜ DSL
        dsl_path = Path("examples/editing_dsl.ai_workflow.json")
        dsl_path.write_text(
            json.dumps(dsl, ensure_ascii=False, indent=2),
            encoding="utf-8"
        )
        print(f"âœ“ ä¿å­˜åˆ°: {dsl_path}")
        
        # æ˜¾ç¤ºå‰ªè¾‘è®¡åˆ’
        timeline = dsl["editing_plan"]["timeline"]
        print(f"\nå‰ªè¾‘è®¡åˆ’é¢„è§ˆï¼ˆå…± {len(timeline)} ä¸ªç‰‡æ®µï¼‰ï¼š")
        for item in timeline[:5]:
            scene_id = item["scene_id"]
            trim = item["trim_frames"]
            purpose = item.get("purpose", "body")
            text = item.get("overlay_text", "")
            print(f"  {item['order']}. {scene_id} [{trim[0]}-{trim[1]}] ({purpose}) {text}")
        
    except ValueError as e:
        print(f"âœ— LLM è°ƒç”¨å¤±è´¥: {e}")
        print("\nè¯·ç¡®ä¿åœ¨ .env ä¸­é…ç½®äº† OPENAI_API_KEY")
        return False
    
    # ========================================================================
    # Stage 4: DSL â†’ Actionsï¼ˆè½¬æ¢ä¸ºæ‰§è¡ŒåŠ¨ä½œï¼‰
    # ========================================================================
    print("\n[Stage 4] DSL â†’ Actionsï¼ˆè½¬æ¢ä¸ºæ‰§è¡ŒåŠ¨ä½œï¼‰")
    print("-" * 70)
    
    actions = []
    
    # 1. åˆ›å»ºæ—¶é—´çº¿
    resolution_str = dsl["export"]["resolution"]  # "1080x1920"
    width, height = map(int, resolution_str.split("x"))
    
    actions.append(create_timeline(
        name="AI_Generated_Timeline",
        fps=fps,
        resolution={"width": width, "height": height}
    ))
    
    # 2. æ·»åŠ è§†é¢‘ç‰‡æ®µ
    for item in dsl["editing_plan"]["timeline"]:
        scene_id = item["scene_id"]
        trim_frames = item["trim_frames"]
        
        actions.append(append_scene(
            scene_id=scene_id,
            in_frame=trim_frames[0],
            out_frame=trim_frames[1],
            source=primary_clip
        ))
        
        # å¦‚æœæœ‰ overlay_textï¼Œæ·»åŠ æ–‡å­—å åŠ 
        if item.get("overlay_text"):
            duration = trim_frames[1] - trim_frames[0]
            actions.append(add_text_overlay(
                text=item["overlay_text"],
                start_frame=trim_frames[0],
                duration_frames=duration
            ))
    
    # 3. æ¸²æŸ“å­—å¹•
    if dsl["editing_plan"]["subtitles"]["mode"] == "from_transcript":
        style = dsl["editing_plan"]["subtitles"].get("style", "bold_yellow")
        actions.append(render_subtitles(
            transcript_segments=transcript_data["segments"],
            fps=fps,
            style=style
        ))
    
    # 4. æ·»åŠ èƒŒæ™¯éŸ³ä¹ï¼ˆå¦‚æœæœ‰ï¼‰
    music = dsl["editing_plan"].get("music", {})
    if music.get("track_path"):
        actions.append(add_music(
            path=music["track_path"],
            volume_db=music.get("volume_db", -18)
        ))
    
    # 5. å¯¼å‡º
    output_path = "D:/Output/ai_generated_video.mp4"  # è¯·æ›¿æ¢ä¸ºå®é™…è·¯å¾„
    actions.append(export_mp4(
        path=output_path,
        resolution=resolution_str
    ))
    
    print(f"âœ“ ç”Ÿæˆ {len(actions)} ä¸ªæ‰§è¡ŒåŠ¨ä½œ")
    
    # ========================================================================
    # Stage 5: Resolve æ‰§è¡Œå‰ªè¾‘
    # ========================================================================
    print("\n[Stage 5] Resolve æ‰§è¡Œå‰ªè¾‘ï¼ˆè‡ªåŠ¨åŒ–ï¼‰")
    print("-" * 70)
    
    print("æ³¨æ„ï¼šæ­¤æ­¥éª¤éœ€è¦ DaVinci Resolve è¿è¡Œ")
    print("æŒ‰ Enter ç»§ç»­æ‰§è¡Œï¼Œæˆ– Ctrl+C å–æ¶ˆ...")
    try:
        input()
    except KeyboardInterrupt:
        print("\nâœ— ç”¨æˆ·å–æ¶ˆæ‰§è¡Œ")
        return False
    
    print("\næ‰§è¡ŒåŠ¨ä½œåºåˆ—...")
    try:
        trace = run_actions(actions, trace_path="ai_workflow_trace.json")
        
        print("\næ‰§è¡Œç»“æœï¼š")
        for t in trace:
            status = "âœ“" if t["ok"] else "âœ—"
            print(f"{status} {t['action']}: {t['detail']} ({t['took_ms']}ms)")
        
        # æ£€æŸ¥æ˜¯å¦å…¨éƒ¨æˆåŠŸ
        all_ok = all(t["ok"] for t in trace)
        
        if all_ok:
            print("\n" + "=" * 70)
            print("ğŸ‰ å®Œæ•´å·¥ä½œæµæ‰§è¡ŒæˆåŠŸï¼")
            print("=" * 70)
            print(f"\næˆç‰‡å·²å¯¼å‡ºåˆ°: {output_path}")
            print("\nå·¥ä½œæµæ€»ç»“ï¼š")
            print(f"  - è¾“å…¥: {edl_path} + {audio_path}")
            print(f"  - åœºæ™¯: {len(scenes.scenes)} ä¸ª")
            print(f"  - å­—å¹•: {len(transcript.segments)} æ®µ")
            print(f"  - ç‰‡æ®µ: {len(timeline)} ä¸ª")
            print(f"  - è¾“å‡º: {output_path}")
        else:
            print("\nâœ— éƒ¨åˆ†åŠ¨ä½œæ‰§è¡Œå¤±è´¥ï¼Œè¯·æŸ¥çœ‹ trace")
        
    except Exception as e:
        print(f"\nâœ— æ‰§è¡Œå¤±è´¥: {e}")
        return False
    
    return True


if __name__ == "__main__":
    print("\næç¤ºï¼š")
    print("- è¯·ç¡®ä¿ DaVinci Resolve æ­£åœ¨è¿è¡Œ")
    print("- è¯·åœ¨ .env ä¸­é…ç½® OPENAI_API_KEY")
    print("- è¯·æ›¿æ¢ç¤ºä¾‹ä¸­çš„æ–‡ä»¶è·¯å¾„ä¸ºå®é™…è·¯å¾„")
    print("\næŒ‰ Enter å¼€å§‹æ¼”ç¤º...")
    try:
        input()
        ai_workflow_demo()
    except KeyboardInterrupt:
        print("\næ¼”ç¤ºå–æ¶ˆ")
