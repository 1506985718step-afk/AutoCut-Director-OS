"""
AutoCut Director - å®Œæ•´æµæ°´çº¿è„šæœ¬

ä¸€é”®æ‰§è¡Œå®Œæ•´çš„ AI é©±åŠ¨è§†é¢‘å‰ªè¾‘æµç¨‹ï¼š
1. åˆ†æç´ æï¼ˆEDL â†’ scenes.json + Audio â†’ transcript.jsonï¼‰
2. AI ç”Ÿæˆå‰ªè¾‘è„šæœ¬ï¼ˆLLM â†’ editing_dsl.jsonï¼‰
3. æ‰§è¡Œå‰ªè¾‘ï¼ˆDSL â†’ Actions â†’ Resolve â†’ æˆç‰‡ï¼‰
"""
import asyncio
import json
import sys
from pathlib import Path
from datetime import datetime

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
from app.tools.scene_from_edl import parse_edl_to_scenes
from app.tools.asr_whisper import transcribe_audio
from app.tools.srt_generator import transcript_to_srt, dsl_to_srt_files
from app.core.llm_engine import LLMDirector
from app.models.schemas import ScenesJSON, TranscriptJSON, DSLValidator
from app.executor.actions import (
    create_timeline,
    append_scene,
    create_text_layer,
    render_subtitles,
    add_music,
    export_mp4
)
from app.executor.runner import run_actions


class Pipeline:
    """å®Œæ•´æµæ°´çº¿ç®¡ç†å™¨"""
    
    def __init__(self, config: dict):
        """
        åˆå§‹åŒ–æµæ°´çº¿
        
        Args:
            config: é…ç½®å­—å…¸ {
                "edl_path": "input.edl",
                "audio_path": "input.mp4",
                "primary_clip_path": "D:/Footage/input.mp4",
                "fps": 30,
                "style": "æŠ–éŸ³çˆ†æ¬¾é£æ ¼",
                "output_path": "D:/Output/final.mp4",
                "output_dir": "output"
            }
        """
        self.config = config
        self.output_dir = Path(config.get("output_dir", "output"))
        self.output_dir.mkdir(exist_ok=True)
        
        # ä¸­é—´äº§ç‰©è·¯å¾„
        self.scenes_path = self.output_dir / "scenes.json"
        self.transcript_path = self.output_dir / "transcript.json"
        self.dsl_path = self.output_dir / "editing_dsl.json"
        self.trace_path = self.output_dir / "trace.json"
        
        # æ•°æ®å­˜å‚¨
        self.scenes = None
        self.transcript = None
        self.dsl = None
        self.trace = None
    
    def print_stage(self, stage: int, title: str):
        """æ‰“å°é˜¶æ®µæ ‡é¢˜"""
        print("\n" + "=" * 70)
        print(f"{stage}ï¸âƒ£  {title}")
        print("=" * 70)
    
    def print_success(self, message: str):
        """æ‰“å°æˆåŠŸæ¶ˆæ¯"""
        print(f"âœ… {message}")
    
    def print_error(self, message: str):
        """æ‰“å°é”™è¯¯æ¶ˆæ¯"""
        print(f"âŒ {message}")
    
    def print_info(self, message: str):
        """æ‰“å°ä¿¡æ¯æ¶ˆæ¯"""
        print(f"â„¹ï¸  {message}")
    
    async def stage_1_analyze(self):
        """é˜¶æ®µ 1: åˆ†æç´ æ"""
        self.print_stage(1, "åˆ†æç´ æ - EDL + Audio â†’ scenes.json + transcript.json")
        
        # 1.1 è§£æ EDL
        print("\nğŸ“¹ è§£æ EDL æ–‡ä»¶...")
        try:
            edl_path = self.config["edl_path"]
            fps = self.config.get("fps", 30)
            primary_clip = self.config["primary_clip_path"]
            
            scenes_data = parse_edl_to_scenes(edl_path, fps, primary_clip)
            self.scenes = ScenesJSON(**scenes_data)
            
            # ä¿å­˜ scenes.json
            self.scenes_path.write_text(
                json.dumps(scenes_data, ensure_ascii=False, indent=2),
                encoding="utf-8"
            )
            
            self.print_success(f"è§£ææˆåŠŸï¼Œç”Ÿæˆ {len(self.scenes.scenes)} ä¸ªåœºæ™¯")
            for scene in self.scenes.scenes[:3]:
                print(f"   - {scene.scene_id}: {scene.start_tc} â†’ {scene.end_tc}")
            if len(self.scenes.scenes) > 3:
                print(f"   ... å…± {len(self.scenes.scenes)} ä¸ªåœºæ™¯")
            
            self.print_info(f"å·²ä¿å­˜: {self.scenes_path}")
            
        except Exception as e:
            self.print_error(f"EDL è§£æå¤±è´¥: {e}")
            return False
        
        # 1.2 è½¬å½•éŸ³é¢‘
        print("\nğŸ¤ è½¬å½•éŸ³é¢‘æ–‡ä»¶...")
        try:
            audio_path = self.config["audio_path"]
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰ transcript
            if self.transcript_path.exists():
                self.print_info("å‘ç°å·²æœ‰ transcript.jsonï¼Œè·³è¿‡è½¬å½•")
                transcript_data = json.loads(self.transcript_path.read_text(encoding="utf-8"))
            else:
                self.print_info("ä½¿ç”¨ Whisper è½¬å½•éŸ³é¢‘ï¼ˆå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...")
                transcript_data = transcribe_audio(
                    audio_path,
                    model=self.config.get("whisper_model", "base"),
                    language=self.config.get("language", "zh")
                )
                
                # ä¿å­˜ transcript.json
                self.transcript_path.write_text(
                    json.dumps(transcript_data, ensure_ascii=False, indent=2),
                    encoding="utf-8"
                )
            
            self.transcript = TranscriptJSON(**transcript_data)
            
            self.print_success(f"è½¬å½•æˆåŠŸï¼Œç”Ÿæˆ {len(self.transcript.segments)} æ®µå­—å¹•")
            for seg in self.transcript.segments[:3]:
                print(f"   - [{seg.start:.1f}s] {seg.text}")
            if len(self.transcript.segments) > 3:
                print(f"   ... å…± {len(self.transcript.segments)} æ®µ")
            
            self.print_info(f"å·²ä¿å­˜: {self.transcript_path}")
            
        except Exception as e:
            self.print_error(f"éŸ³é¢‘è½¬å½•å¤±è´¥: {e}")
            return False
        
        return True
    
    async def stage_2_generate_dsl(self):
        """é˜¶æ®µ 2: AI ç”Ÿæˆå‰ªè¾‘è„šæœ¬"""
        self.print_stage(2, "AI å¯¼æ¼”æ„æ€ - LLM â†’ editing_dsl.json")
        
        print("\nğŸ§  è°ƒç”¨ LLM ç”Ÿæˆå‰ªè¾‘è„šæœ¬...")
        try:
            director = LLMDirector()
            style_prompt = self.config.get("style", "æŠ–éŸ³çˆ†æ¬¾é£æ ¼ï¼šèŠ‚å¥å¿«ã€æ–‡å­—å¤šã€å¼ºè°ƒå…³é”®è¯")
            
            self.print_info(f"é£æ ¼: {style_prompt}")
            self.print_info("æ­£åœ¨ç”Ÿæˆ...")
            
            dsl_data = director.generate_editing_dsl(
                scenes=self.scenes,
                transcript=self.transcript,
                style_prompt=style_prompt
            )
            
            self.dsl = dsl_data
            
            # ä¿å­˜ DSL
            self.dsl_path.write_text(
                json.dumps(dsl_data, ensure_ascii=False, indent=2),
                encoding="utf-8"
            )
            
            self.print_success("AI ç”ŸæˆæˆåŠŸï¼")
            
            # æ˜¾ç¤ºå‰ªè¾‘è®¡åˆ’
            timeline = dsl_data["editing_plan"]["timeline"]
            print(f"\nğŸ“‹ å‰ªè¾‘è®¡åˆ’ï¼ˆå…± {len(timeline)} ä¸ªç‰‡æ®µï¼‰:")
            for item in timeline[:5]:
                scene_id = item["scene_id"]
                trim = item["trim_frames"]
                purpose = item.get("purpose", "body")
                text = item.get("overlay_text", "")
                print(f"   {item['order']}. {scene_id} [{trim[0]}-{trim[1]}] ({purpose}) {text}")
            if len(timeline) > 5:
                print(f"   ... å…± {len(timeline)} ä¸ªç‰‡æ®µ")
            
            self.print_info(f"å·²ä¿å­˜: {self.dsl_path}")
            
        except Exception as e:
            self.print_error(f"LLM ç”Ÿæˆå¤±è´¥: {e}")
            self.print_info("è¯·æ£€æŸ¥ .env ä¸­çš„ OPENAI_API_KEY é…ç½®")
            return False
        
        # éªŒè¯ DSL
        print("\nğŸ” éªŒè¯ DSL ç¡¬è§„åˆ™...")
        try:
            scenes_data = json.loads(self.scenes_path.read_text(encoding="utf-8"))
            errors = DSLValidator.validate_dsl_against_scenes(dsl_data, scenes_data)
            
            if errors:
                self.print_error("éªŒè¯å¤±è´¥ï¼ˆAI å¹»è§‰æ£€æµ‹ï¼‰:")
                for err in errors:
                    print(f"   - {err}")
                return False
            
            self.print_success("éªŒè¯é€šè¿‡ï¼AI æ²¡æœ‰å¹»è§‰")
            
        except Exception as e:
            self.print_error(f"éªŒè¯å¤±è´¥: {e}")
            return False
        
        return True
    
    async def stage_3_execute(self):
        """é˜¶æ®µ 3: æ‰§è¡Œå‰ªè¾‘"""
        self.print_stage(3, "DaVinci Resolve æ‰§è¡Œ - DSL â†’ Actions â†’ æˆç‰‡")
        
        print("\nğŸ¬ è½¬æ¢ DSL ä¸ºæ‰§è¡ŒåŠ¨ä½œ...")
        try:
            actions = self._dsl_to_actions()
            self.print_success(f"ç”Ÿæˆ {len(actions)} ä¸ªæ‰§è¡ŒåŠ¨ä½œ")
            
        except Exception as e:
            self.print_error(f"DSL è½¬æ¢å¤±è´¥: {e}")
            return False
        
        # æ£€æŸ¥ Resolve
        print("\nğŸ”Œ è¿æ¥ DaVinci Resolve...")
        self.print_info("è¯·ç¡®ä¿ DaVinci Resolve æ­£åœ¨è¿è¡Œ")
        
        try:
            from app.executor.resolve_adapter import connect_resolve
            resolve, proj = connect_resolve()
            self.print_success("è¿æ¥æˆåŠŸï¼")
            
        except Exception as e:
            self.print_error(f"è¿æ¥å¤±è´¥: {e}")
            self.print_info("è¯·å¯åŠ¨ DaVinci Resolve å¹¶æ‰“å¼€é¡¹ç›®")
            return False
        
        # æ‰§è¡ŒåŠ¨ä½œ
        print("\nâš™ï¸  æ‰§è¡Œå‰ªè¾‘åŠ¨ä½œ...")
        try:
            self.trace = run_actions(actions, trace_path=str(self.trace_path))
            
            # æ˜¾ç¤ºæ‰§è¡Œç»“æœ
            print("\nğŸ“Š æ‰§è¡Œç»“æœ:")
            for t in self.trace:
                status = "âœ…" if t["ok"] else "âŒ"
                print(f"   {status} {t['action']}: {t['detail']} ({t['took_ms']}ms)")
            
            # æ£€æŸ¥æ˜¯å¦å…¨éƒ¨æˆåŠŸ
            all_ok = all(t["ok"] for t in self.trace)
            
            if all_ok:
                self.print_success("æ‰€æœ‰åŠ¨ä½œæ‰§è¡ŒæˆåŠŸï¼")
            else:
                self.print_error("éƒ¨åˆ†åŠ¨ä½œæ‰§è¡Œå¤±è´¥")
                return False
            
            self.print_info(f"æ‰§è¡Œæ—¥å¿—: {self.trace_path}")
            
        except Exception as e:
            self.print_error(f"æ‰§è¡Œå¤±è´¥: {e}")
            return False
        
        return True
    
    def _dsl_to_actions(self):
        """å°† DSL è½¬æ¢ä¸º Action åˆ—è¡¨"""
        actions = []
        
        dsl = self.dsl
        scenes_data = json.loads(self.scenes_path.read_text(encoding="utf-8"))
        transcript_data = json.loads(self.transcript_path.read_text(encoding="utf-8"))
        
        fps = self.config.get("fps", 30)
        
        # 1. åˆ›å»ºæ—¶é—´çº¿
        resolution_str = dsl["export"]["resolution"]  # "1080x1920"
        width, height = map(int, resolution_str.split("x"))
        
        actions.append(create_timeline(
            name=f"AutoCut_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            fps=fps,
            resolution={"width": width, "height": height}
        ))
        
        # 2. æ·»åŠ è§†é¢‘ç‰‡æ®µ
        primary_clip = self.config["primary_clip_path"]
        
        for item in dsl["editing_plan"]["timeline"]:
            scene_id = item["scene_id"]
            trim_frames = item["trim_frames"]
            
            actions.append(append_scene(
                scene_id=scene_id,
                in_frame=trim_frames[0],
                out_frame=trim_frames[1],
                source=primary_clip
            ))
        
        # 3. æ·»åŠ æ–‡å­—å åŠ ï¼ˆå¦‚æœæœ‰ï¼‰
        text_items = []
        for item in dsl["editing_plan"]["timeline"]:
            if item.get("overlay_text"):
                text_items.append({
                    "content": item["overlay_text"],
                    "start_frame": item["trim_frames"][0],
                    "duration_frames": item["trim_frames"][1] - item["trim_frames"][0]
                })
        
        if text_items:
            actions.append(create_text_layer(
                text_items=text_items,
                track_index=3
            ))
        
        # 4. æ¸²æŸ“å­—å¹•
        if dsl["editing_plan"]["subtitles"]["mode"] == "from_transcript":
            style = dsl["editing_plan"]["subtitles"].get("style", "bold_yellow")
            actions.append(render_subtitles(
                transcript_segments=transcript_data["segments"],
                fps=fps,
                style=style
            ))
        
        # 5. æ·»åŠ èƒŒæ™¯éŸ³ä¹ï¼ˆå¦‚æœæœ‰ï¼‰
        music = dsl["editing_plan"].get("music", {})
        if music.get("track_path"):
            actions.append(add_music(
                path=music["track_path"],
                volume_db=music.get("volume_db", -18)
            ))
        
        # 6. å¯¼å‡º
        output_path = self.config.get("output_path", "D:/Output/autocut_output.mp4")
        actions.append(export_mp4(
            path=output_path,
            resolution=resolution_str
        ))
        
        return actions
    
    async def run(self):
        """è¿è¡Œå®Œæ•´æµæ°´çº¿"""
        print("\n" + "ğŸ¬" * 35)
        print("AutoCut Director - AI é©±åŠ¨çš„è‡ªåŠ¨è§†é¢‘å‰ªè¾‘ç³»ç»Ÿ")
        print("ğŸ¬" * 35)
        
        start_time = datetime.now()
        
        # é˜¶æ®µ 1: åˆ†æç´ æ
        if not await self.stage_1_analyze():
            self.print_error("æµæ°´çº¿ä¸­æ–­ï¼šåˆ†æç´ æå¤±è´¥")
            return False
        
        # é˜¶æ®µ 2: AI ç”Ÿæˆ
        if not await self.stage_2_generate_dsl():
            self.print_error("æµæ°´çº¿ä¸­æ–­ï¼šAI ç”Ÿæˆå¤±è´¥")
            return False
        
        # é˜¶æ®µ 3: æ‰§è¡Œå‰ªè¾‘
        if not await self.stage_3_execute():
            self.print_error("æµæ°´çº¿ä¸­æ–­ï¼šæ‰§è¡Œå‰ªè¾‘å¤±è´¥")
            return False
        
        # å®Œæˆ
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        print("\n" + "=" * 70)
        print("ğŸ‰ æµæ°´çº¿æ‰§è¡Œå®Œæˆï¼")
        print("=" * 70)
        
        print(f"\nâ±ï¸  æ€»è€—æ—¶: {duration:.1f} ç§’")
        print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
        print(f"   - åœºæ™¯: {self.scenes_path}")
        print(f"   - è½¬å½•: {self.transcript_path}")
        print(f"   - DSL: {self.dsl_path}")
        print(f"   - æ‰§è¡Œæ—¥å¿—: {self.trace_path}")
        print(f"   - æˆç‰‡: {self.config.get('output_path', 'N/A')}")
        
        print(f"\nâœ¨ æˆç‰‡å·²ç”Ÿæˆï¼Œè¯·åœ¨ DaVinci Resolve ä¸­æŸ¥çœ‹ï¼")
        
        return True


async def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®
    config = {
        # è¾“å…¥æ–‡ä»¶
        "edl_path": "examples/test.edl",
        "audio_path": "D:/Footage/input.mp4",  # è¯·æ›¿æ¢ä¸ºå®é™…è·¯å¾„
        "primary_clip_path": "D:/Footage/input.mp4",  # è¯·æ›¿æ¢ä¸ºå®é™…è·¯å¾„
        
        # å‚æ•°
        "fps": 30,
        "language": "zh",
        "whisper_model": "base",
        
        # é£æ ¼
        "style": "æŠ–éŸ³çˆ†æ¬¾é£æ ¼ï¼šèŠ‚å¥å¿«ã€æ–‡å­—å¤šã€å¼ºè°ƒå…³é”®è¯",
        
        # è¾“å‡º
        "output_path": "D:/Output/autocut_final.mp4",  # è¯·æ›¿æ¢ä¸ºå®é™…è·¯å¾„
        "output_dir": "output"
    }
    
    # ä»å‘½ä»¤è¡Œå‚æ•°è¯»å–é…ç½®ï¼ˆå¯é€‰ï¼‰
    if len(sys.argv) > 1:
        import argparse
        parser = argparse.ArgumentParser(description="AutoCut Director Pipeline")
        parser.add_argument("--edl", help="EDL æ–‡ä»¶è·¯å¾„")
        parser.add_argument("--audio", help="éŸ³é¢‘æ–‡ä»¶è·¯å¾„")
        parser.add_argument("--clip", help="ä¸»è§†é¢‘ç‰‡æ®µè·¯å¾„")
        parser.add_argument("--fps", type=int, default=30, help="å¸§ç‡")
        parser.add_argument("--style", help="å‰ªè¾‘é£æ ¼")
        parser.add_argument("--output", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
        
        args = parser.parse_args()
        
        if args.edl:
            config["edl_path"] = args.edl
        if args.audio:
            config["audio_path"] = args.audio
        if args.clip:
            config["primary_clip_path"] = args.clip
        if args.fps:
            config["fps"] = args.fps
        if args.style:
            config["style"] = args.style
        if args.output:
            config["output_path"] = args.output
    
    # è¿è¡Œæµæ°´çº¿
    pipeline = Pipeline(config)
    success = await pipeline.run()
    
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    asyncio.run(main())
